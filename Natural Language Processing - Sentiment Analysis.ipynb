{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this notebook we will use classification models to predicate how good is our model to predict whether a reviewer liked a restaurant solely on the basis of their review\n",
    "** The data file has 1000 reviews and for each review there is a Liked value indicating whether the reviewer liked it or not. We will take 800 reviews to train our model and then use 200 remaining reviewes to see how good the predictions are. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tm)\n",
    "library(SnowballC)\n",
    "library(caTools)\n",
    "library(randomForest)\n",
    "library(e1071)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "dataset_original = read.delim('Restaurant_Reviews.tsv', quote = '', stringsAsFactors = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Review</th><th scope=col>Liked</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Wow... Loved this place.                                                               </td><td>1                                                                                      </td></tr>\n",
       "\t<tr><td>Crust is not good.                                                                     </td><td>0                                                                                      </td></tr>\n",
       "\t<tr><td>Not tasty and the texture was just nasty.                                              </td><td>0                                                                                      </td></tr>\n",
       "\t<tr><td>Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.</td><td>1                                                                                      </td></tr>\n",
       "\t<tr><td>The selection on the menu was great and so were the prices.                            </td><td>1                                                                                      </td></tr>\n",
       "\t<tr><td>Now I am getting angry and I want my damn pho.                                         </td><td>0                                                                                      </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       " Review & Liked\\\\\n",
       "\\hline\n",
       "\t Wow... Loved this place.                                                                & 1                                                                                      \\\\\n",
       "\t Crust is not good.                                                                      & 0                                                                                      \\\\\n",
       "\t Not tasty and the texture was just nasty.                                               & 0                                                                                      \\\\\n",
       "\t Stopped by during the late May bank holiday off Rick Steve recommendation and loved it. & 1                                                                                      \\\\\n",
       "\t The selection on the menu was great and so were the prices.                             & 1                                                                                      \\\\\n",
       "\t Now I am getting angry and I want my damn pho.                                          & 0                                                                                      \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "Review | Liked | \n",
       "|---|---|---|---|---|---|\n",
       "| Wow... Loved this place.                                                                | 1                                                                                       | \n",
       "| Crust is not good.                                                                      | 0                                                                                       | \n",
       "| Not tasty and the texture was just nasty.                                               | 0                                                                                       | \n",
       "| Stopped by during the late May bank holiday off Rick Steve recommendation and loved it. | 1                                                                                       | \n",
       "| The selection on the menu was great and so were the prices.                             | 1                                                                                       | \n",
       "| Now I am getting angry and I want my damn pho.                                          | 0                                                                                       | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  Review                                                                                 \n",
       "1 Wow... Loved this place.                                                               \n",
       "2 Crust is not good.                                                                     \n",
       "3 Not tasty and the texture was just nasty.                                              \n",
       "4 Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.\n",
       "5 The selection on the menu was great and so were the prices.                            \n",
       "6 Now I am getting angry and I want my damn pho.                                         \n",
       "  Liked\n",
       "1 1    \n",
       "2 0    \n",
       "3 0    \n",
       "4 1    \n",
       "5 1    \n",
       "6 0    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(dataset_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'row 1:Wow... Loved this place.'"
      ],
      "text/latex": [
       "'row 1:Wow... Loved this place.'"
      ],
      "text/markdown": [
       "'row 1:Wow... Loved this place.'"
      ],
      "text/plain": [
       "[1] \"row 1:Wow... Loved this place.\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'row 841:for 40 bucks a head, i really expect better food.'"
      ],
      "text/latex": [
       "'row 841:for 40 bucks a head, i really expect better food.'"
      ],
      "text/markdown": [
       "'row 841:for 40 bucks a head, i really expect better food.'"
      ],
      "text/plain": [
       "[1] \"row 841:for 40 bucks a head, i really expect better food.\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# before cleanup\n",
    "paste(\"row 1:\", as.character(corpus[[1]]), sep=\"\")\n",
    "paste(\"row 841:\", as.character(corpus[[841]]), sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean text\n",
    "# build corpus from Review column\n",
    "corpus = VCorpus(VectorSource(dataset_original$Review))\n",
    "# convert everything to lowercase\n",
    "corpus = tm_map(corpus, content_transformer(tolower))\n",
    "# remove numbers like 1, 50, etc.\n",
    "corpus = tm_map(corpus, removeNumbers)\n",
    "# remove punctuations like ',', '...', ':', etc.\n",
    "corpus = tm_map(corpus, removePunctuation)\n",
    "# remove stop words like i, me, we, it, have, can't, etc.\n",
    "# you can add your own stopwords\n",
    "corpus = tm_map(corpus, removeWords, stopwords())\n",
    "#orpus = tm_map(corpus, removeWords, c('ours', 'he'))\n",
    "# stem words (get the root of each word) loved to love\n",
    "corpus = tm_map(corpus, stemDocument)\n",
    "# remove whitespace\n",
    "corpus = tm_map(corpus, stripWhitespace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'row 1:wow love place'"
      ],
      "text/latex": [
       "'row 1:wow love place'"
      ],
      "text/markdown": [
       "'row 1:wow love place'"
      ],
      "text/plain": [
       "[1] \"row 1:wow love place\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'row 841:buck head realli expect better food'"
      ],
      "text/latex": [
       "'row 841:buck head realli expect better food'"
      ],
      "text/markdown": [
       "'row 841:buck head realli expect better food'"
      ],
      "text/plain": [
       "[1] \"row 841:buck head realli expect better food\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# after cleanup\n",
    "paste(\"row 1:\", as.character(corpus[[1]]), sep=\"\")\n",
    "paste(\"row 841:\", as.character(corpus[[841]]), sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<<DocumentTermMatrix (documents: 1000, terms: 1577)>>\n",
       "Non-/sparse entries: 5435/1571565\n",
       "Sparsity           : 100%\n",
       "Maximal term length: 32\n",
       "Weighting          : term frequency (tf)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of 6\n",
      " $ i       : int [1:5435] 1 1 1 2 2 3 3 3 3 4 ...\n",
      " $ j       : int [1:5435] 800 1032 1557 323 589 746 904 1362 1374 90 ...\n",
      " $ v       : num [1:5435] 1 1 1 1 1 1 1 1 1 1 ...\n",
      " $ nrow    : int 1000\n",
      " $ ncol    : int 1577\n",
      " $ dimnames:List of 2\n",
      "  ..$ Docs : chr [1:1000] \"1\" \"2\" \"3\" \"4\" ...\n",
      "  ..$ Terms: chr [1:1577] \"absolut\" \"absolutley\" \"accid\" \"accommod\" ...\n",
      " - attr(*, \"class\")= chr [1:2] \"DocumentTermMatrix\" \"simple_triplet_matrix\"\n",
      " - attr(*, \"weighting\")= chr [1:2] \"term frequency\" \"tf\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>1000</li>\n",
       "\t<li>1577</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1000\n",
       "\\item 1577\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1000\n",
       "2. 1577\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1000 1577"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating the Bag of Words model\n",
    "dtm = DocumentTermMatrix(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<DocumentTermMatrix (documents: 1000, terms: 1577)>>\n",
      "Non-/sparse entries: 5435/1571565\n",
      "Sparsity           : 100%\n",
      "Maximal term length: 32\n",
      "Weighting          : term frequency (tf)\n",
      "List of 6\n",
      " $ i       : int [1:5435] 1 1 1 2 2 3 3 3 3 4 ...\n",
      " $ j       : int [1:5435] 800 1032 1557 323 589 746 904 1362 1374 90 ...\n",
      " $ v       : num [1:5435] 1 1 1 1 1 1 1 1 1 1 ...\n",
      " $ nrow    : int 1000\n",
      " $ ncol    : int 1577\n",
      " $ dimnames:List of 2\n",
      "  ..$ Docs : chr [1:1000] \"1\" \"2\" \"3\" \"4\" ...\n",
      "  ..$ Terms: chr [1:1577] \"absolut\" \"absolutley\" \"accid\" \"accommod\" ...\n",
      " - attr(*, \"class\")= chr [1:2] \"DocumentTermMatrix\" \"simple_triplet_matrix\"\n",
      " - attr(*, \"weighting\")= chr [1:2] \"term frequency\" \"tf\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>1000</li>\n",
       "\t<li>1577</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1000\n",
       "\\item 1577\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1000\n",
       "2. 1577\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1000 1577"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We'll have a very large sparse matrix (many columns with 0 values)\n",
    "print(dtm)\n",
    "str(dtm)\n",
    "dim(dtm) # notice it has 1000 rows and 1577 columns!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<<DocumentTermMatrix (documents: 1000, terms: 691)>>\n",
       "Non-/sparse entries: 4549/686451\n",
       "Sparsity           : 99%\n",
       "Maximal term length: 12\n",
       "Weighting          : term frequency (tf)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>1000</li>\n",
       "\t<li>691</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1000\n",
       "\\item 691\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1000\n",
       "2. 691\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1000  691"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# so let's remove the sparse terms\n",
    "dtm = removeSparseTerms(dtm, 0.999) # keep 99% of all words with 1\n",
    "dtm\n",
    "dim(dtm)\n",
    "# now columns reduced to 691 but sparsity is still very high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for classification we need a data frame\n",
    "dataset = as.data.frame(as.matrix(dtm))\n",
    "# add the dependent variable (Liked) to this new dataframe that is a copy of the original df\n",
    "dataset$Liked = dataset_original$Liked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>absolut</th><th scope=col>acknowledg</th><th scope=col>actual</th><th scope=col>ago</th><th scope=col>almost</th><th scope=col>also</th><th scope=col>although</th><th scope=col>alway</th><th scope=col>amaz</th><th scope=col>ambianc</th><th scope=col>...</th><th scope=col>wow</th><th scope=col>wrap</th><th scope=col>wrong</th><th scope=col>year</th><th scope=col>yet</th><th scope=col>youd</th><th scope=col>your</th><th scope=col>yummi</th><th scope=col>zero</th><th scope=col>Liked</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>...</td><td>1  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>1  </td></tr>\n",
       "\t<tr><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>...</td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td></tr>\n",
       "\t<tr><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>...</td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td></tr>\n",
       "\t<tr><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>...</td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>1  </td></tr>\n",
       "\t<tr><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>...</td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>1  </td></tr>\n",
       "\t<tr><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>...</td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td><td>0  </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll}\n",
       " absolut & acknowledg & actual & ago & almost & also & although & alway & amaz & ambianc & ... & wow & wrap & wrong & year & yet & youd & your & yummi & zero & Liked\\\\\n",
       "\\hline\n",
       "\t 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & ... & 1   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 1  \\\\\n",
       "\t 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & ... & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0  \\\\\n",
       "\t 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & ... & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0  \\\\\n",
       "\t 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & ... & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 1  \\\\\n",
       "\t 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & ... & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 1  \\\\\n",
       "\t 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & ... & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0   & 0  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "absolut | acknowledg | actual | ago | almost | also | although | alway | amaz | ambianc | ... | wow | wrap | wrong | year | yet | youd | your | yummi | zero | Liked | \n",
       "|---|---|---|---|---|---|\n",
       "| 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | ... | 1   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 1   | \n",
       "| 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | ... | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | \n",
       "| 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | ... | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | \n",
       "| 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | ... | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 1   | \n",
       "| 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | ... | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 1   | \n",
       "| 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | ... | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | 0   | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  absolut acknowledg actual ago almost also although alway amaz ambianc ... wow\n",
       "1 0       0          0      0   0      0    0        0     0    0       ... 1  \n",
       "2 0       0          0      0   0      0    0        0     0    0       ... 0  \n",
       "3 0       0          0      0   0      0    0        0     0    0       ... 0  \n",
       "4 0       0          0      0   0      0    0        0     0    0       ... 0  \n",
       "5 0       0          0      0   0      0    0        0     0    0       ... 0  \n",
       "6 0       0          0      0   0      0    0        0     0    0       ... 0  \n",
       "  wrap wrong year yet youd your yummi zero Liked\n",
       "1 0    0     0    0   0    0    0     0    1    \n",
       "2 0    0     0    0   0    0    0     0    0    \n",
       "3 0    0     0    0   0    0    0     0    0    \n",
       "4 0    0     0    0   0    0    0     0    1    \n",
       "5 0    0     0    0   0    0    0     0    1    \n",
       "6 0    0     0    0   0    0    0     0    0    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(dataset)\n",
    "# sparce matrix ... mostly all 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Encoding the target feature as factor\n",
    "dataset$Liked = factor(dataset$Liked, levels = c(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "set.seed(123)\n",
    "split = sample.split(dataset$Liked, SplitRatio = 0.8)\n",
    "training_set = subset(dataset, split == TRUE)\n",
    "test_set = subset(dataset, split == FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fitting Random Forest Classification to the Training set\n",
    "classifier = randomForest(x = training_set[-692],\n",
    "                          y = training_set$Liked,\n",
    "                          ntree = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = predict(classifier, newdata = test_set[-692])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   y_pred\n",
       "     0  1\n",
       "  0 66 34\n",
       "  1 24 76"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "cm = table(test_set[, 692], y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Accuracy: 0.73'"
      ],
      "text/latex": [
       "'Accuracy: 0.73'"
      ],
      "text/markdown": [
       "'Accuracy: 0.73'"
      ],
      "text/plain": [
       "[1] \"Accuracy: 0.73\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'Precision: 0.739583333333333'"
      ],
      "text/latex": [
       "'Precision: 0.739583333333333'"
      ],
      "text/markdown": [
       "'Precision: 0.739583333333333'"
      ],
      "text/plain": [
       "[1] \"Precision: 0.739583333333333\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'Recall: 0.71'"
      ],
      "text/latex": [
       "'Recall: 0.71'"
      ],
      "text/markdown": [
       "'Recall: 0.71'"
      ],
      "text/plain": [
       "[1] \"Recall: 0.71\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Evaluation\n",
    "# TP True Positives, TN True Negatives, FP False Positives, FN False Negatives\n",
    "# Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "# Precision = TP / (TP + FP)\n",
    "# Recall = TP / (TP + FN)\n",
    "TP = cm[4]\n",
    "TN = cm[1]\n",
    "FP = cm[3]\n",
    "FN = cm[2]\n",
    "\n",
    "paste(\"Accuracy: \", (TP + TN) / (TP + TN + FP + FN), sep=\"\")\n",
    "paste(\"Precision: \",TP / (TP + FP), sep=\"\")\n",
    "paste(\"Recall: \", TP / (TP + FN), sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** With Naive Bayes Classification **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Naive Bayes Classification to the Training set\n",
    "nbclassifier = naiveBayes(x = training_set[-692],\n",
    "                        y = training_set$Liked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = predict(nbclassifier, newdata = test_set[-692])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   y_pred\n",
       "     0  1\n",
       "  0  5 95\n",
       "  1  4 96"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "cm = table(test_set[, 692], y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Accuracy: 0.505'"
      ],
      "text/latex": [
       "'Accuracy: 0.505'"
      ],
      "text/markdown": [
       "'Accuracy: 0.505'"
      ],
      "text/plain": [
       "[1] \"Accuracy: 0.505\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'Precision: 0.50261780104712'"
      ],
      "text/latex": [
       "'Precision: 0.50261780104712'"
      ],
      "text/markdown": [
       "'Precision: 0.50261780104712'"
      ],
      "text/plain": [
       "[1] \"Precision: 0.50261780104712\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'Recall: 0.96'"
      ],
      "text/latex": [
       "'Recall: 0.96'"
      ],
      "text/markdown": [
       "'Recall: 0.96'"
      ],
      "text/plain": [
       "[1] \"Recall: 0.96\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Evaluation\n",
    "# TP True Positives, TN True Negatives, FP False Positives, FN False Negatives\n",
    "# Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "# Precision = TP / (TP + FP)\n",
    "# Recall = TP / (TP + FN)\n",
    "TP = cm[4]\n",
    "TN = cm[1]\n",
    "FP = cm[3]\n",
    "FN = cm[2]\n",
    "\n",
    "paste(\"Accuracy: \", (TP + TN) / (TP + TN + FP + FN), sep=\"\")\n",
    "paste(\"Precision: \",TP / (TP + FP), sep=\"\")\n",
    "paste(\"Recall: \", TP / (TP + FN), sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** With Support Vector Machine Classification **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in svm.default(x, y, scale = scale, ..., na.action = na.action):\n",
      "\"Variable(s) 'boot' and 'brick' and 'eye' and 'given' and 'legit' and 'mall' and 'oven' and 'peanut' and 'pure' and 'scallop' and 'show' and 'tap' constant. Cannot scale data.\""
     ]
    }
   ],
   "source": [
    "svmclassifier = svm(formula = Liked ~ .,\n",
    "                 data = training_set,\n",
    "                 type = 'C-classification',\n",
    "                 kernel = 'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = predict(svmclassifier, newdata = test_set[-692])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   y_pred\n",
       "     0  1\n",
       "  0 78 22\n",
       "  1 19 81"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "cm = table(test_set[, 692], y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Accuracy: 0.795'"
      ],
      "text/latex": [
       "'Accuracy: 0.795'"
      ],
      "text/markdown": [
       "'Accuracy: 0.795'"
      ],
      "text/plain": [
       "[1] \"Accuracy: 0.795\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'Precision: 0.786407766990291'"
      ],
      "text/latex": [
       "'Precision: 0.786407766990291'"
      ],
      "text/markdown": [
       "'Precision: 0.786407766990291'"
      ],
      "text/plain": [
       "[1] \"Precision: 0.786407766990291\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'Recall: 0.81'"
      ],
      "text/latex": [
       "'Recall: 0.81'"
      ],
      "text/markdown": [
       "'Recall: 0.81'"
      ],
      "text/plain": [
       "[1] \"Recall: 0.81\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Evaluation\n",
    "# TP True Positives, TN True Negatives, FP False Positives, FN False Negatives\n",
    "# Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "# Precision = TP / (TP + FP)\n",
    "# Recall = TP / (TP + FN)\n",
    "TP = cm[4]\n",
    "TN = cm[1]\n",
    "FP = cm[3]\n",
    "FN = cm[2]\n",
    "\n",
    "paste(\"Accuracy: \", (TP + TN) / (TP + TN + FP + FN), sep=\"\")\n",
    "paste(\"Precision: \",TP / (TP + FP), sep=\"\")\n",
    "paste(\"Recall: \", TP / (TP + FN), sep=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
